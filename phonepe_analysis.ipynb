{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcc55d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371998f2",
   "metadata": {},
   "source": [
    "Extracting Data from JSON filre to Data Frame in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56339ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 5,034 rows written to: /Users/kishore_kumar/PhonePe/pulse/csv_out/aggregated_transactions.csv\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ---- set your base path (ABSOLUTE) ----\n",
    "BASE = Path(\"/Users/kishore_kumar/PhonePe/pulse/data/aggregated/transaction/country/india/state\")\n",
    "\n",
    "if not BASE.exists():\n",
    "    raise FileNotFoundError(f\"Base path not found: {BASE}\")\n",
    "\n",
    "rows = {\n",
    "    'State': [], 'Year': [], 'Quarter': [],\n",
    "    'Transaction_type': [], 'Transaction_count': [], 'Transaction_amount': []\n",
    "}\n",
    "\n",
    "# walk: state -> year -> quarter.json\n",
    "for state_dir in sorted([d for d in BASE.iterdir() if d.is_dir()]):\n",
    "    state = state_dir.name\n",
    "    for year_dir in sorted([d for d in state_dir.iterdir() if d.is_dir()]):\n",
    "        year = int(year_dir.name)\n",
    "        for qfile in sorted([f for f in year_dir.iterdir() if f.suffix == \".json\"], key=lambda p: int(p.stem)):\n",
    "            try:\n",
    "                with qfile.open(\"r\", encoding=\"utf-8\") as f:\n",
    "                    js = json.load(f)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] skip {qfile}: {e}\")\n",
    "                continue\n",
    "\n",
    "            txn_list = (js or {}).get(\"data\", {}).get(\"transactionData\", []) or []\n",
    "            for item in txn_list:\n",
    "                name = item.get(\"name\")\n",
    "                instruments = item.get(\"paymentInstruments\", []) or []\n",
    "\n",
    "                # Prefer TOTAL; if missing, sum all instruments\n",
    "                total_count, total_amount = None, None\n",
    "                for inst in instruments:\n",
    "                    if inst.get(\"type\") == \"TOTAL\":\n",
    "                        total_count = inst.get(\"count\")\n",
    "                        total_amount = inst.get(\"amount\")\n",
    "                        break\n",
    "                if total_count is None:\n",
    "                    total_count = sum((inst.get(\"count\") or 0) for inst in instruments)\n",
    "                    total_amount = sum((inst.get(\"amount\") or 0.0) for inst in instruments)\n",
    "\n",
    "                rows['State'].append(state)\n",
    "                rows['Year'].append(year)\n",
    "                rows['Quarter'].append(int(qfile.stem))\n",
    "                rows['Transaction_type'].append(name)\n",
    "                rows['Transaction_count'].append(total_count)\n",
    "                rows['Transaction_amount'].append(total_amount)\n",
    "\n",
    "df_aggregated_transaction = pd.DataFrame(rows)\n",
    "\n",
    "# ---- Save CSV (make sure the directory exists) ----\n",
    "out_dir = Path(\"/Users/kishore_kumar/PhonePe/pulse/csv_out\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "out_csv = out_dir / \"aggregated_transactions.csv\"\n",
    "\n",
    "if df_aggregated_transaction.empty:\n",
    "    print(\"[INFO] No rows parsed — check the BASE path or JSON structure.\")\n",
    "else:\n",
    "    df_aggregated_transaction.sort_values(\n",
    "        ['State', 'Year', 'Quarter', 'Transaction_type'],\n",
    "        inplace=True, ignore_index=True\n",
    "    )\n",
    "    df_aggregated_transaction.to_csv(out_csv, index=False)\n",
    "    print(f\"[OK] {len(df_aggregated_transaction):,} rows written to: {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b29caf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 682 rows -> /Users/kishore_kumar/PhonePe/pulse/csv_out/aggregated_insurance.csv\n"
     ]
    }
   ],
   "source": [
    "#Aggregated Insurance\n",
    "import os, json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_INS = Path(\"/Users/kishore_kumar/PhonePe/pulse/data/aggregated/insurance/country/india/state\")\n",
    "OUT_DIR = Path(\"/Users/kishore_kumar/PhonePe/pulse/csv_out\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "rows_ins = {\n",
    "    'State': [], 'Year': [], 'Quarter': [],\n",
    "    'Insurance_type': [], 'Insurance_count': [], 'Insurance_amount': []\n",
    "}\n",
    "\n",
    "if not BASE_INS.exists():\n",
    "    raise FileNotFoundError(f\"Base path not found: {BASE_INS}\")\n",
    "\n",
    "for state_dir in sorted([d for d in BASE_INS.iterdir() if d.is_dir()]):\n",
    "    state = state_dir.name\n",
    "    for year_dir in sorted([d for d in state_dir.iterdir() if d.is_dir()]):\n",
    "        year = int(year_dir.name)\n",
    "        for qfile in sorted([f for f in year_dir.iterdir() if f.suffix == \".json\"], key=lambda p: int(p.stem)):\n",
    "            with qfile.open(\"r\", encoding=\"utf-8\") as f:\n",
    "                js = json.load(f)\n",
    "\n",
    "            txn_list = (js or {}).get(\"data\", {}).get(\"transactionData\", []) or []\n",
    "            for item in txn_list:\n",
    "                name = item.get(\"name\")\n",
    "                instruments = item.get(\"paymentInstruments\", []) or []\n",
    "\n",
    "                # Prefer TOTAL; else sum\n",
    "                total_count, total_amount = None, None\n",
    "                for inst in instruments:\n",
    "                    if inst.get(\"type\") == \"TOTAL\":\n",
    "                        total_count = inst.get(\"count\")\n",
    "                        total_amount = inst.get(\"amount\")\n",
    "                        break\n",
    "                if total_count is None:\n",
    "                    total_count = sum((inst.get(\"count\") or 0) for inst in instruments)\n",
    "                    total_amount = sum((inst.get(\"amount\") or 0.0) for inst in instruments)\n",
    "\n",
    "                rows_ins['State'].append(state)\n",
    "                rows_ins['Year'].append(year)\n",
    "                rows_ins['Quarter'].append(int(qfile.stem))\n",
    "                rows_ins['Insurance_type'].append(name)\n",
    "                rows_ins['Insurance_count'].append(total_count)\n",
    "                rows_ins['Insurance_amount'].append(total_amount)\n",
    "\n",
    "df_insurance = pd.DataFrame(rows_ins).sort_values(['State','Year','Quarter','Insurance_type'], ignore_index=True)\n",
    "out_ins = OUT_DIR / \"aggregated_insurance.csv\"\n",
    "df_insurance.to_csv(out_ins, index=False)\n",
    "print(f\"[OK] {len(df_insurance):,} rows -> {out_ins}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81d5150b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 1,008 rows -> /Users/kishore_kumar/PhonePe/pulse/csv_out/aggregated_users.csv\n",
      "[OK] 6,732 rows -> /Users/kishore_kumar/PhonePe/pulse/csv_out/aggregated_users_by_device.csv\n"
     ]
    }
   ],
   "source": [
    "#Aggregated User\n",
    "import os, json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_USER = Path(\"/Users/kishore_kumar/PhonePe/pulse/data/aggregated/user/country/india/state\")\n",
    "OUT_DIR = Path(\"/Users/kishore_kumar/PhonePe/pulse/csv_out\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "rows_user_tot = {'State':[], 'Year':[], 'Quarter':[], 'Registered_users':[], 'App_opens':[]}\n",
    "rows_user_dev = {'State':[], 'Year':[], 'Quarter':[], 'Brand':[], 'Brand_count':[], 'Brand_pct':[]}\n",
    "\n",
    "if not BASE_USER.exists():\n",
    "    raise FileNotFoundError(f\"Base path not found: {BASE_USER}\")\n",
    "\n",
    "for state_dir in sorted([d for d in BASE_USER.iterdir() if d.is_dir()]):\n",
    "    state = state_dir.name\n",
    "    for year_dir in sorted([d for d in state_dir.iterdir() if d.is_dir()]):\n",
    "        year = int(year_dir.name)\n",
    "        for qfile in sorted([f for f in year_dir.iterdir() if f.suffix == \".json\"], key=lambda p: int(p.stem)):\n",
    "            with qfile.open(\"r\", encoding=\"utf-8\") as f:\n",
    "                js = json.load(f)\n",
    "\n",
    "            data = (js or {}).get(\"data\", {}) or {}\n",
    "            agg = data.get(\"aggregated\", {}) or {}\n",
    "            users_by_device = data.get(\"usersByDevice\", []) or []\n",
    "\n",
    "            # totals\n",
    "            rows_user_tot['State'].append(state)\n",
    "            rows_user_tot['Year'].append(year)\n",
    "            rows_user_tot['Quarter'].append(int(qfile.stem))\n",
    "            rows_user_tot['Registered_users'].append(agg.get(\"registeredUsers\"))\n",
    "            rows_user_tot['App_opens'].append(agg.get(\"appOpens\"))\n",
    "\n",
    "            # devices\n",
    "            for d in users_by_device:\n",
    "                rows_user_dev['State'].append(state)\n",
    "                rows_user_dev['Year'].append(year)\n",
    "                rows_user_dev['Quarter'].append(int(qfile.stem))\n",
    "                rows_user_dev['Brand'].append(d.get(\"brand\"))\n",
    "                rows_user_dev['Brand_count'].append(d.get(\"count\"))\n",
    "                rows_user_dev['Brand_pct'].append(d.get(\"percentage\"))\n",
    "\n",
    "df_user_tot = pd.DataFrame(rows_user_tot).sort_values(['State','Year','Quarter'], ignore_index=True)\n",
    "df_user_dev = pd.DataFrame(rows_user_dev).sort_values(['State','Year','Quarter','Brand'], ignore_index=True)\n",
    "\n",
    "out_user_tot = OUT_DIR / \"aggregated_users.csv\"\n",
    "out_user_dev = OUT_DIR / \"aggregated_users_by_device.csv\"\n",
    "df_user_tot.to_csv(out_user_tot, index=False)\n",
    "df_user_dev.to_csv(out_user_dev, index=False)\n",
    "print(f\"[OK] {len(df_user_tot):,} rows -> {out_user_tot}\")\n",
    "print(f\"[OK] {len(df_user_dev):,} rows -> {out_user_dev}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "755ba4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 20,604 rows -> /Users/kishore_kumar/PhonePe/pulse/csv_out/map_transactions.csv\n"
     ]
    }
   ],
   "source": [
    "#map transaction\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Per README: data/map/transaction/hover/country/india/state/<state>/<year>/<quarter>.json\n",
    "# (district-level details per state-year-quarter)\n",
    "BASE = Path(\"/Users/kishore_kumar/PhonePe/pulse/data/map/transaction/hover/country/india/state\")\n",
    "OUT = Path(\"/Users/kishore_kumar/PhonePe/pulse/csv_out\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not BASE.exists():\n",
    "    raise FileNotFoundError(f\"Path not found (check the 'hover' segment): {BASE}\")\n",
    "\n",
    "rows = {'State':[], 'Year':[], 'Quarter':[], 'Name':[], 'Metric_type':[], 'Count':[], 'Amount':[]}\n",
    "\n",
    "for state_dir in sorted([d for d in BASE.iterdir() if d.is_dir()]):\n",
    "    state = state_dir.name\n",
    "    for year_dir in sorted([d for d in state_dir.iterdir() if d.is_dir()]):\n",
    "        year = int(year_dir.name)\n",
    "        for qfile in sorted([f for f in year_dir.iterdir() if f.suffix==\".json\"], key=lambda p: int(p.stem)):\n",
    "            with qfile.open(\"r\", encoding=\"utf-8\") as f:\n",
    "                js = json.load(f)\n",
    "            hover_list = (js or {}).get(\"data\", {}).get(\"hoverDataList\", []) or []\n",
    "            for h in hover_list:\n",
    "                name = h.get(\"name\")\n",
    "                for m in (h.get(\"metric\") or []):\n",
    "                    rows['State'].append(state)\n",
    "                    rows['Year'].append(year)\n",
    "                    rows['Quarter'].append(int(qfile.stem))\n",
    "                    rows['Name'].append(name)\n",
    "                    rows['Metric_type'].append(m.get(\"type\"))\n",
    "                    rows['Count'].append(m.get(\"count\"))\n",
    "                    rows['Amount'].append(m.get(\"amount\"))\n",
    "\n",
    "df_map_txn = pd.DataFrame(rows).sort_values(['State','Year','Quarter','Name','Metric_type'], ignore_index=True)\n",
    "out_csv = OUT / \"map_transactions.csv\"\n",
    "df_map_txn.to_csv(out_csv, index=False)\n",
    "print(f\"[OK] {len(df_map_txn):,} rows -> {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8082164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 13,876 rows -> /Users/kishore_kumar/PhonePe/pulse/csv_out/map_insurance.csv\n"
     ]
    }
   ],
   "source": [
    "#map Insurance\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Per README: data/map/insurance/hover/country/india/state/<state>/<year>/<quarter>.json\n",
    "BASE = Path(\"/Users/kishore_kumar/PhonePe/pulse/data/map/insurance/hover/country/india/state\")\n",
    "OUT = Path(\"/Users/kishore_kumar/PhonePe/pulse/csv_out\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not BASE.exists():\n",
    "    raise FileNotFoundError(f\"Path not found (check the 'hover' segment): {BASE}\")\n",
    "\n",
    "rows = {'State':[], 'Year':[], 'Quarter':[], 'Name':[], 'Metric_type':[], 'Count':[], 'Amount':[]}\n",
    "\n",
    "for state_dir in sorted([d for d in BASE.iterdir() if d.is_dir()]):\n",
    "    state = state_dir.name\n",
    "    for year_dir in sorted([d for d in state_dir.iterdir() if d.is_dir()]):\n",
    "        year = int(year_dir.name)\n",
    "        for qfile in sorted([f for f in year_dir.iterdir() if f.suffix==\".json\"], key=lambda p: int(p.stem)):\n",
    "            with qfile.open(\"r\", encoding=\"utf-8\") as f:\n",
    "                js = json.load(f)\n",
    "            hover_list = (js or {}).get(\"data\", {}).get(\"hoverDataList\", []) or []\n",
    "            for h in hover_list:\n",
    "                name = h.get(\"name\")\n",
    "                for m in (h.get(\"metric\") or []):\n",
    "                    rows['State'].append(state)\n",
    "                    rows['Year'].append(year)\n",
    "                    rows['Quarter'].append(int(qfile.stem))\n",
    "                    rows['Name'].append(name)\n",
    "                    rows['Metric_type'].append(m.get(\"type\"))\n",
    "                    rows['Count'].append(m.get(\"count\"))\n",
    "                    rows['Amount'].append(m.get(\"amount\"))\n",
    "\n",
    "df_map_ins = pd.DataFrame(rows).sort_values(['State','Year','Quarter','Name','Metric_type'], ignore_index=True)\n",
    "out_csv = OUT / \"map_insurance.csv\"\n",
    "df_map_ins.to_csv(out_csv, index=False)\n",
    "print(f\"[OK] {len(df_map_ins):,} rows -> {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e121d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 20,608 rows -> /Users/kishore_kumar/PhonePe/pulse/csv_out/map_users.csv\n"
     ]
    }
   ],
   "source": [
    "#map user\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Per README: data/map/user/hover/country/india/state/<state>/<year>/<quarter>.json\n",
    "BASE = Path(\"/Users/kishore_kumar/PhonePe/pulse/data/map/user/hover/country/india/state\")\n",
    "OUT = Path(\"/Users/kishore_kumar/PhonePe/pulse/csv_out\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not BASE.exists():\n",
    "    raise FileNotFoundError(f\"Path not found (check the 'hover' segment): {BASE}\")\n",
    "\n",
    "rows = {'State':[], 'Year':[], 'Quarter':[], 'Name':[], 'Registered_users':[], 'App_opens':[]}\n",
    "\n",
    "for state_dir in sorted([d for d in BASE.iterdir() if d.is_dir()]):\n",
    "    state = state_dir.name\n",
    "    for year_dir in sorted([d for d in state_dir.iterdir() if d.is_dir()]):\n",
    "        year = int(year_dir.name)\n",
    "        for qfile in sorted([f for f in year_dir.iterdir() if f.suffix==\".json\"], key=lambda p: int(p.stem)):\n",
    "            with qfile.open(\"r\", encoding=\"utf-8\") as f:\n",
    "                js = json.load(f)\n",
    "            hover = (js or {}).get(\"data\", {}).get(\"hoverData\", {}) or {}\n",
    "            for name, v in hover.items():\n",
    "                rows['State'].append(state)\n",
    "                rows['Year'].append(year)\n",
    "                rows['Quarter'].append(int(qfile.stem))\n",
    "                rows['Name'].append(name)\n",
    "                rows['Registered_users'].append((v or {}).get(\"registeredUsers\"))\n",
    "                rows['App_opens'].append((v or {}).get(\"appOpens\"))\n",
    "\n",
    "df_map_user = pd.DataFrame(rows).sort_values(['State','Year','Quarter','Name'], ignore_index=True)\n",
    "out_csv = OUT / \"map_users.csv\"\n",
    "df_map_user.to_csv(out_csv, index=False)\n",
    "print(f\"[OK] {len(df_map_user):,} rows -> {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77fc2138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 20,604 rows -> /Users/kishore_kumar/PhonePe/pulse/map_transactions_state.csv\n",
      "[OK] 13,876 rows -> /Users/kishore_kumar/PhonePe/pulse/map_insurance_state.csv\n",
      "[OK] 20,608 rows -> /Users/kishore_kumar/PhonePe/pulse/map_users_state.csv\n",
      "[OK] 1,008 rows -> /Users/kishore_kumar/PhonePe/pulse/map_transactions_country.csv\n",
      "[OK] 682 rows -> /Users/kishore_kumar/PhonePe/pulse/map_insurance_country.csv\n",
      "[OK] 1,008 rows -> /Users/kishore_kumar/PhonePe/pulse/map_users_country.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# ---- Adjust these two paths only ----\n",
    "ROOT = Path(\"/Users/kishore_kumar/PhonePe/pulse/data\")  # repo's data/ path\n",
    "OUT  = Path(\"/Users/kishore_kumar/PhonePe/pulse\")\n",
    "\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Helpers\n",
    "def _safe_int(s): \n",
    "    try: return int(s)\n",
    "    except: return None\n",
    "\n",
    "def _iter_quarters(dir_path: Path):\n",
    "    \"\"\"Yield quarter files sorted by integer stem.\"\"\"\n",
    "    qfiles = [f for f in dir_path.iterdir() if f.suffix == \".json\"]\n",
    "    return sorted(qfiles, key=lambda p: _safe_int(p.stem) if p.stem.isdigit() else 999)\n",
    "\n",
    "# ---------- STATE LEVEL ----------\n",
    "def map_transaction_state():\n",
    "    base = ROOT / \"map\" / \"transaction\" / \"hover\" / \"country\" / \"india\" / \"state\"\n",
    "    if not base.exists(): \n",
    "        raise FileNotFoundError(f\"Not found: {base}\")\n",
    "\n",
    "    rows = {'State':[], 'Year':[], 'Quarter':[], 'Name':[], 'Metric_type':[], 'Count':[], 'Amount':[]}\n",
    "\n",
    "    for state_dir in sorted([d for d in base.iterdir() if d.is_dir()]):\n",
    "        state = state_dir.name\n",
    "        for year_dir in sorted([d for d in state_dir.iterdir() if d.is_dir()], key=lambda p: int(p.name)):\n",
    "            year = int(year_dir.name)\n",
    "            for qfile in _iter_quarters(year_dir):\n",
    "                with qfile.open(\"r\", encoding=\"utf-8\") as f:\n",
    "                    js = json.load(f)\n",
    "                hover_list = (js or {}).get(\"data\", {}).get(\"hoverDataList\", []) or []\n",
    "                for h in hover_list:\n",
    "                    name = h.get(\"name\")\n",
    "                    for m in (h.get(\"metric\") or []):\n",
    "                        rows['State'].append(state)\n",
    "                        rows['Year'].append(year)\n",
    "                        rows['Quarter'].append(int(qfile.stem))\n",
    "                        rows['Name'].append(name)\n",
    "                        rows['Metric_type'].append(m.get(\"type\"))\n",
    "                        rows['Count'].append(m.get(\"count\"))\n",
    "                        rows['Amount'].append(m.get(\"amount\"))\n",
    "\n",
    "    df = pd.DataFrame(rows).sort_values(['State','Year','Quarter','Name','Metric_type'], ignore_index=True)\n",
    "    out = OUT / \"map_transactions_state.csv\"\n",
    "    df.to_csv(out, index=False)\n",
    "    print(f\"[OK] {len(df):,} rows -> {out}\")\n",
    "\n",
    "def map_insurance_state():\n",
    "    base = ROOT / \"map\" / \"insurance\" / \"hover\" / \"country\" / \"india\" / \"state\"\n",
    "    if not base.exists(): \n",
    "        raise FileNotFoundError(f\"Not found: {base}\")\n",
    "\n",
    "    rows = {'State':[], 'Year':[], 'Quarter':[], 'Name':[], 'Metric_type':[], 'Count':[], 'Amount':[]}\n",
    "\n",
    "    for state_dir in sorted([d for d in base.iterdir() if d.is_dir()]):\n",
    "        state = state_dir.name\n",
    "        for year_dir in sorted([d for d in state_dir.iterdir() if d.is_dir()], key=lambda p: int(p.name)):\n",
    "            year = int(year_dir.name)\n",
    "            for qfile in _iter_quarters(year_dir):\n",
    "                with qfile.open(\"r\", encoding=\"utf-8\") as f:\n",
    "                    js = json.load(f)\n",
    "                hover_list = (js or {}).get(\"data\", {}).get(\"hoverDataList\", []) or []\n",
    "                for h in hover_list:\n",
    "                    name = h.get(\"name\")\n",
    "                    for m in (h.get(\"metric\") or []):\n",
    "                        rows['State'].append(state)\n",
    "                        rows['Year'].append(year)\n",
    "                        rows['Quarter'].append(int(qfile.stem))\n",
    "                        rows['Name'].append(name)\n",
    "                        rows['Metric_type'].append(m.get(\"type\"))\n",
    "                        rows['Count'].append(m.get(\"count\"))\n",
    "                        rows['Amount'].append(m.get(\"amount\"))\n",
    "\n",
    "    df = pd.DataFrame(rows).sort_values(['State','Year','Quarter','Name','Metric_type'], ignore_index=True)\n",
    "    out = OUT / \"map_insurance_state.csv\"\n",
    "    df.to_csv(out, index=False)\n",
    "    print(f\"[OK] {len(df):,} rows -> {out}\")\n",
    "\n",
    "def map_user_state():\n",
    "    base = ROOT / \"map\" / \"user\" / \"hover\" / \"country\" / \"india\" / \"state\"\n",
    "    if not base.exists(): \n",
    "        raise FileNotFoundError(f\"Not found: {base}\")\n",
    "\n",
    "    rows = {'State':[], 'Year':[], 'Quarter':[], 'Name':[], 'Registered_users':[], 'App_opens':[]}\n",
    "\n",
    "    for state_dir in sorted([d for d in base.iterdir() if d.is_dir()]):\n",
    "        state = state_dir.name\n",
    "        for year_dir in sorted([d for d in state_dir.iterdir() if d.is_dir()], key=lambda p: int(p.name)):\n",
    "            year = int(year_dir.name)\n",
    "            for qfile in _iter_quarters(year_dir):\n",
    "                with qfile.open(\"r\", encoding=\"utf-8\") as f:\n",
    "                    js = json.load(f)\n",
    "                hover = (js or {}).get(\"data\", {}).get(\"hoverData\", {}) or {}\n",
    "                for name, v in hover.items():\n",
    "                    rows['State'].append(state)\n",
    "                    rows['Year'].append(year)\n",
    "                    rows['Quarter'].append(int(qfile.stem))\n",
    "                    rows['Name'].append(name)\n",
    "                    rows['Registered_users'].append((v or {}).get(\"registeredUsers\"))\n",
    "                    rows['App_opens'].append((v or {}).get(\"appOpens\"))\n",
    "\n",
    "    df = pd.DataFrame(rows).sort_values(['State','Year','Quarter','Name'], ignore_index=True)\n",
    "    out = OUT / \"map_users_state.csv\"\n",
    "    df.to_csv(out, index=False)\n",
    "    print(f\"[OK] {len(df):,} rows -> {out}\")\n",
    "\n",
    "# ---------- COUNTRY LEVEL ----------\n",
    "def map_transaction_country():\n",
    "    base = ROOT / \"map\" / \"transaction\" / \"hover\" / \"country\" / \"india\"\n",
    "    if not base.exists(): \n",
    "        raise FileNotFoundError(f\"Not found: {base}\")\n",
    "\n",
    "    rows = {'Year':[], 'Quarter':[], 'Name':[], 'Metric_type':[], 'Count':[], 'Amount':[]}\n",
    "\n",
    "    # layout: .../india/<year>/<quarter>.json\n",
    "    for year_dir in sorted([d for d in base.iterdir() if d.is_dir() and d.name != \"state\"], key=lambda p: int(p.name)):\n",
    "        year = int(year_dir.name)\n",
    "        for qfile in _iter_quarters(year_dir):\n",
    "            with qfile.open(\"r\", encoding=\"utf-8\") as f:\n",
    "                js = json.load(f)\n",
    "            hover_list = (js or {}).get(\"data\", {}).get(\"hoverDataList\", []) or []\n",
    "            for h in hover_list:\n",
    "                name = h.get(\"name\")\n",
    "                for m in (h.get(\"metric\") or []):\n",
    "                    rows['Year'].append(year)\n",
    "                    rows['Quarter'].append(int(qfile.stem))\n",
    "                    rows['Name'].append(name)\n",
    "                    rows['Metric_type'].append(m.get(\"type\"))\n",
    "                    rows['Count'].append(m.get(\"count\"))\n",
    "                    rows['Amount'].append(m.get(\"amount\"))\n",
    "\n",
    "    df = pd.DataFrame(rows).sort_values(['Year','Quarter','Name','Metric_type'], ignore_index=True)\n",
    "    out = OUT / \"map_transactions_country.csv\"\n",
    "    df.to_csv(out, index=False)\n",
    "    print(f\"[OK] {len(df):,} rows -> {out}\")\n",
    "\n",
    "def map_insurance_country():\n",
    "    base = ROOT / \"map\" / \"insurance\" / \"hover\" / \"country\" / \"india\"\n",
    "    if not base.exists(): \n",
    "        raise FileNotFoundError(f\"Not found: {base}\")\n",
    "\n",
    "    rows = {'Year':[], 'Quarter':[], 'Name':[], 'Metric_type':[], 'Count':[], 'Amount':[]}\n",
    "\n",
    "    for year_dir in sorted([d for d in base.iterdir() if d.is_dir() and d.name != \"state\"], key=lambda p: int(p.name)):\n",
    "        year = int(year_dir.name)\n",
    "        for qfile in _iter_quarters(year_dir):\n",
    "            with qfile.open(\"r\", encoding=\"utf-8\") as f:\n",
    "                js = json.load(f)\n",
    "            hover_list = (js or {}).get(\"data\", {}).get(\"hoverDataList\", []) or []\n",
    "            for h in hover_list:\n",
    "                name = h.get(\"name\")\n",
    "                for m in (h.get(\"metric\") or []):\n",
    "                    rows['Year'].append(year)\n",
    "                    rows['Quarter'].append(int(qfile.stem))\n",
    "                    rows['Name'].append(name)\n",
    "                    rows['Metric_type'].append(m.get(\"type\"))\n",
    "                    rows['Count'].append(m.get(\"count\"))\n",
    "                    rows['Amount'].append(m.get(\"amount\"))\n",
    "\n",
    "    df = pd.DataFrame(rows).sort_values(['Year','Quarter','Name','Metric_type'], ignore_index=True)\n",
    "    out = OUT / \"map_insurance_country.csv\"\n",
    "    df.to_csv(out, index=False)\n",
    "    print(f\"[OK] {len(df):,} rows -> {out}\")\n",
    "\n",
    "def map_user_country():\n",
    "    base = ROOT / \"map\" / \"user\" / \"hover\" / \"country\" / \"india\"\n",
    "    if not base.exists(): \n",
    "        raise FileNotFoundError(f\"Not found: {base}\")\n",
    "\n",
    "    rows = {'Year':[], 'Quarter':[], 'Name':[], 'Registered_users':[], 'App_opens':[]}\n",
    "\n",
    "    for year_dir in sorted([d for d in base.iterdir() if d.is_dir() and d.name != \"state\"], key=lambda p: int(p.name)):\n",
    "        year = int(year_dir.name)\n",
    "        for qfile in _iter_quarters(year_dir):\n",
    "            with qfile.open(\"r\", encoding=\"utf-8\") as f:\n",
    "                js = json.load(f)\n",
    "            hover = (js or {}).get(\"data\", {}).get(\"hoverData\", {}) or {}\n",
    "            for name, v in hover.items():\n",
    "                rows['Year'].append(year)\n",
    "                rows['Quarter'].append(int(qfile.stem))\n",
    "                rows['Name'].append(name)\n",
    "                rows['Registered_users'].append((v or {}).get(\"registeredUsers\"))\n",
    "                rows['App_opens'].append((v or {}).get(\"appOpens\"))\n",
    "\n",
    "    df = pd.DataFrame(rows).sort_values(['Year','Quarter','Name'], ignore_index=True)\n",
    "    out = OUT / \"map_users_country.csv\"\n",
    "    df.to_csv(out, index=False)\n",
    "    print(f\"[OK] {len(df):,} rows -> {out}\")\n",
    "\n",
    "# Run all\n",
    "if __name__ == \"__main__\":\n",
    "    map_transaction_state()\n",
    "    map_insurance_state()\n",
    "    map_user_state()\n",
    "    map_transaction_country()\n",
    "    map_insurance_country()\n",
    "    map_user_country()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58bf28f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 12,276 rows -> /Users/kishore_kumar/PhonePe/pulse/csv_out/top_insurance_state_combined.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# ======= Set your paths =======\n",
    "ROOT = Path(\"/Users/kishore_kumar/PhonePe/pulse/data\")   # path to repo's data/ folder\n",
    "OUT  = Path(\"/Users/kishore_kumar/PhonePe/pulse/csv_out\")\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _safe_int(s):\n",
    "    try: return int(s)\n",
    "    except: return None\n",
    "\n",
    "def _iter_quarters(dir_path: Path):\n",
    "    qfiles = [f for f in dir_path.iterdir() if f.suffix == \".json\"]\n",
    "    return sorted(qfiles, key=lambda p: _safe_int(p.stem) if p.stem.isdigit() else 999)\n",
    "\n",
    "rows = []\n",
    "\n",
    "# ---------- STATE LEVEL ONLY ----------\n",
    "base_state = ROOT / \"top\" / \"insurance\" / \"country\" / \"india\" / \"state\"\n",
    "if not base_state.exists():\n",
    "    raise FileNotFoundError(f\"Not found: {base_state}\")\n",
    "\n",
    "for state_dir in sorted([d for d in base_state.iterdir() if d.is_dir()]):\n",
    "    state = state_dir.name\n",
    "    for year_dir in sorted([d for d in state_dir.iterdir() if d.is_dir()], key=lambda p: int(p.name)):\n",
    "        year = int(year_dir.name)\n",
    "        for qfile in _iter_quarters(year_dir):\n",
    "            with qfile.open(\"r\", encoding=\"utf-8\") as f:\n",
    "                js = json.load(f)\n",
    "            data = (js or {}).get(\"data\", {}) or {}\n",
    "\n",
    "            # DISTRICTS\n",
    "            for e in data.get(\"districts\", []) or []:\n",
    "                m = e.get(\"metric\", {}) or {}\n",
    "                rows.append({\n",
    "                    \"State\": state,\n",
    "                    \"Entity_Level\": \"district\",\n",
    "                    \"Entity\": e.get(\"entityName\"),\n",
    "                    \"Metric_type\": m.get(\"type\"),\n",
    "                    \"Count\": m.get(\"count\"),\n",
    "                    \"Amount\": m.get(\"amount\"),\n",
    "                    \"Year\": year,\n",
    "                    \"Quarter\": int(qfile.stem),\n",
    "                })\n",
    "\n",
    "            # PINCODES\n",
    "            for e in data.get(\"pincodes\", []) or []:\n",
    "                m = e.get(\"metric\", {}) or {}\n",
    "                rows.append({\n",
    "                    \"State\": state,\n",
    "                    \"Entity_Level\": \"pincode\",\n",
    "                    \"Entity\": e.get(\"entityName\"),\n",
    "                    \"Metric_type\": m.get(\"type\"),\n",
    "                    \"Count\": m.get(\"count\"),\n",
    "                    \"Amount\": m.get(\"amount\"),\n",
    "                    \"Year\": year,\n",
    "                    \"Quarter\": int(qfile.stem),\n",
    "                })\n",
    "\n",
    "# ---------- Build & write ----------\n",
    "df = pd.DataFrame(rows)\n",
    "if df.empty:\n",
    "    print(\"[INFO] No rows parsed — check paths and repo contents.\")\n",
    "else:\n",
    "    df.sort_values([\"State\",\"Year\",\"Quarter\",\"Entity_Level\",\"Entity\"], inplace=True, ignore_index=True)\n",
    "    out_csv = OUT / \"top_insurance_state_combined.csv\"\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"[OK] {len(df):,} rows -> {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83beefa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 18,295 rows -> /Users/kishore_kumar/PhonePe/pulse/csv_out/top_transactions_state_combined.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# ======= Set your paths =======\n",
    "ROOT = Path(\"/Users/kishore_kumar/PhonePe/pulse/data\")   # path to repo's data/ folder\n",
    "OUT  = Path(\"/Users/kishore_kumar/PhonePe/pulse/csv_out\")\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _safe_int(s):\n",
    "    try: return int(s)\n",
    "    except: return None\n",
    "\n",
    "def _iter_quarters(dir_path: Path):\n",
    "    qfiles = [f for f in dir_path.iterdir() if f.suffix == \".json\"]\n",
    "    return sorted(qfiles, key=lambda p: _safe_int(p.stem) if p.stem.isdigit() else 999)\n",
    "\n",
    "# ---------- Top → Transactions (STATE)  ----------\n",
    "def build_top_transactions_state_combined():\n",
    "    base_state = ROOT / \"top\" / \"transaction\" / \"country\" / \"india\" / \"state\"\n",
    "    if not base_state.exists():\n",
    "        raise FileNotFoundError(f\"Not found: {base_state}\")\n",
    "\n",
    "    rows = []\n",
    "    for state_dir in sorted([d for d in base_state.iterdir() if d.is_dir()]):\n",
    "        state = state_dir.name\n",
    "        for year_dir in sorted([d for d in state_dir.iterdir() if d.is_dir()], key=lambda p: int(p.name)):\n",
    "            year = int(year_dir.name)\n",
    "            for qfile in _iter_quarters(year_dir):\n",
    "                with qfile.open(\"r\", encoding=\"utf-8\") as f:\n",
    "                    js = json.load(f)\n",
    "                data = (js or {}).get(\"data\", {}) or {}\n",
    "\n",
    "                # DISTRICTS\n",
    "                for e in data.get(\"districts\", []) or []:\n",
    "                    m = e.get(\"metric\", {}) or {}\n",
    "                    rows.append({\n",
    "                        \"State\": state,\n",
    "                        \"Entity_Level\": \"district\",\n",
    "                        \"Entity\": e.get(\"entityName\"),\n",
    "                        \"Metric_type\": m.get(\"type\"),\n",
    "                        \"Count\": m.get(\"count\"),\n",
    "                        \"Amount\": m.get(\"amount\"),\n",
    "                        \"Year\": year,\n",
    "                        \"Quarter\": int(qfile.stem),\n",
    "                    })\n",
    "\n",
    "                # PINCODES\n",
    "                for e in data.get(\"pincodes\", []) or []:\n",
    "                    m = e.get(\"metric\", {}) or {}\n",
    "                    rows.append({\n",
    "                        \"State\": state,\n",
    "                        \"Entity_Level\": \"pincode\",\n",
    "                        \"Entity\": e.get(\"entityName\"),\n",
    "                        \"Metric_type\": m.get(\"type\"),\n",
    "                        \"Count\": m.get(\"count\"),\n",
    "                        \"Amount\": m.get(\"amount\"),\n",
    "                        \"Year\": year,\n",
    "                        \"Quarter\": int(qfile.stem),\n",
    "                    })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        print(\"[INFO] Transactions (state) — no rows parsed. Check paths.\")\n",
    "        return\n",
    "    df.sort_values([\"State\",\"Year\",\"Quarter\",\"Entity_Level\",\"Entity\"], inplace=True, ignore_index=True)\n",
    "    out_csv = OUT / \"top_transactions_state_combined.csv\"\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"[OK] {len(df):,} rows -> {out_csv}\")\n",
    "\n",
    "\n",
    "# ---------- Run ----------\n",
    "if __name__ == \"__main__\":\n",
    "    build_top_transactions_state_combined()\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0a8fd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 18,296 rows -> /Users/kishore_kumar/PhonePe/pulse/csv_out/top_users_state_combined.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# ======= Set your paths =======\n",
    "ROOT = Path(\"/Users/kishore_kumar/PhonePe/pulse/data\")   # path to repo's data/ folder\n",
    "OUT  = Path(\"/Users/kishore_kumar/PhonePe/pulse/csv_out\")\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _safe_int(s):\n",
    "    try: return int(s)\n",
    "    except: return None\n",
    "\n",
    "def _iter_quarters(dir_path: Path):\n",
    "    qfiles = [f for f in dir_path.iterdir() if f.suffix == \".json\"]\n",
    "    return sorted(qfiles, key=lambda p: _safe_int(p.stem) if p.stem.isdigit() else 999)\n",
    "# ---------- Top → Users (STATE) ----------\n",
    "def build_top_users_state_combined():\n",
    "    base_state = ROOT / \"top\" / \"user\" / \"country\" / \"india\" / \"state\"\n",
    "    if not base_state.exists():\n",
    "        raise FileNotFoundError(f\"Not found: {base_state}\")\n",
    "\n",
    "    rows = []\n",
    "    for state_dir in sorted([d for d in base_state.iterdir() if d.is_dir()]):\n",
    "        state = state_dir.name\n",
    "        for year_dir in sorted([d for d in state_dir.iterdir() if d.is_dir()], key=lambda p: int(p.name)):\n",
    "            year = int(year_dir.name)\n",
    "            for qfile in _iter_quarters(year_dir):\n",
    "                with qfile.open(\"r\", encoding=\"utf-8\") as f:\n",
    "                    js = json.load(f)\n",
    "                data = (js or {}).get(\"data\", {}) or {}\n",
    "\n",
    "                # DISTRICTS\n",
    "                for e in data.get(\"districts\", []) or []:\n",
    "                    rows.append({\n",
    "                        \"State\": state,\n",
    "                        \"Entity_Level\": \"district\",\n",
    "                        \"Entity\": e.get(\"name\"),\n",
    "                        \"Registered_users\": e.get(\"registeredUsers\"),\n",
    "                        \"Year\": year,\n",
    "                        \"Quarter\": int(qfile.stem),\n",
    "                    })\n",
    "\n",
    "                # PINCODES\n",
    "                for e in data.get(\"pincodes\", []) or []:\n",
    "                    rows.append({\n",
    "                        \"State\": state,\n",
    "                        \"Entity_Level\": \"pincode\",\n",
    "                        \"Entity\": e.get(\"name\"),\n",
    "                        \"Registered_users\": e.get(\"registeredUsers\"),\n",
    "                        \"Year\": year,\n",
    "                        \"Quarter\": int(qfile.stem),\n",
    "                    })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        print(\"[INFO] Users (state) — no rows parsed. Check paths.\")\n",
    "        return\n",
    "    df.sort_values([\"State\",\"Year\",\"Quarter\",\"Entity_Level\",\"Entity\"], inplace=True, ignore_index=True)\n",
    "    out_csv = OUT / \"top_users_state_combined.csv\"\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"[OK] {len(df):,} rows -> {out_csv}\")\n",
    "\n",
    "# ---------- Run ----------\n",
    "if __name__ == \"__main__\":\n",
    "    build_top_users_state_combined()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be285180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       State Entity_Level         Entity Metric_type  Count  \\\n",
      "0  andaman-&-nicobar-islands     district       nicobars       TOTAL      3   \n",
      "1  andaman-&-nicobar-islands     district  south andaman       TOTAL      3   \n",
      "2  andaman-&-nicobar-islands      pincode         744101       TOTAL      1   \n",
      "3  andaman-&-nicobar-islands      pincode         744104       TOTAL      2   \n",
      "4  andaman-&-nicobar-islands      pincode         744301       TOTAL      3   \n",
      "\n",
      "   Amount  Year  Quarter  \n",
      "0   565.0  2020        2  \n",
      "1   795.0  2020        2  \n",
      "2   282.0  2020        2  \n",
      "3   513.0  2020        2  \n",
      "4   565.0  2020        2  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# adjust the path to your combined CSV\n",
    "df = pd.read_csv(\"/Users/kishore_kumar/PhonePe/pulse/csv_out/top_insurance_state_combined.csv\")\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5649467c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "District rows: 5608\n",
      "Pincode rows: 6668\n"
     ]
    }
   ],
   "source": [
    "# filter by Entity_Level\n",
    "df_districts = df[df[\"Entity_Level\"] == \"district\"].copy()\n",
    "df_pincodes  = df[df[\"Entity_Level\"] == \"pincode\"].copy()\n",
    "\n",
    "print(\"District rows:\", len(df_districts))\n",
    "print(\"Pincode rows:\", len(df_pincodes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04ce9b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote two separate CSVs:\n",
      "/Users/kishore_kumar/PhonePe/pulse/csv_out/top_insurance_state_districts.csv\n",
      "/Users/kishore_kumar/PhonePe/pulse/csv_out/top_insurance_state_pincodes.csv\n"
     ]
    }
   ],
   "source": [
    "out_dir = \"/Users/kishore_kumar/PhonePe/pulse/csv_out\"\n",
    "\n",
    "df_districts.to_csv(f\"{out_dir}/top_insurance_state_districts.csv\", index=False)\n",
    "df_pincodes.to_csv(f\"{out_dir}/top_insurance_state_pincodes.csv\", index=False)\n",
    "\n",
    "print(\"✅ Wrote two separate CSVs:\")\n",
    "print(f\"{out_dir}/top_insurance_state_districts.csv\")\n",
    "print(f\"{out_dir}/top_insurance_state_pincodes.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10564af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       State Entity_Level                    Entity  \\\n",
      "0  andaman-&-nicobar-islands     district                  nicobars   \n",
      "1  andaman-&-nicobar-islands     district  north and middle andaman   \n",
      "2  andaman-&-nicobar-islands     district             south andaman   \n",
      "3  andaman-&-nicobar-islands      pincode                    744101   \n",
      "4  andaman-&-nicobar-islands      pincode                    744102   \n",
      "\n",
      "  Metric_type  Count        Amount  Year  Quarter  \n",
      "0       TOTAL    528  1.139849e+06  2018        1  \n",
      "1       TOTAL    442  9.316631e+05  2018        1  \n",
      "2       TOTAL   5688  1.256025e+07  2018        1  \n",
      "3       TOTAL   1622  2.769298e+06  2018        1  \n",
      "4       TOTAL    969  3.519060e+06  2018        1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# adjust the path to your combined CSV\n",
    "df = pd.read_csv(\"/Users/kishore_kumar/PhonePe/pulse/csv_out/top_transactions_state_combined.csv\")\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3538381d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "District rows: 8296\n",
      "Pincode rows: 9999\n",
      "✅ Wrote two separate CSVs:\n",
      "/Users/kishore_kumar/PhonePe/pulse/csv_out/top_transaction_state_districts.csv\n",
      "/Users/kishore_kumar/PhonePe/pulse/csv_out/top_transaction_state_pincodes.csv\n"
     ]
    }
   ],
   "source": [
    "# filter by Entity_Level\n",
    "df_districts = df[df[\"Entity_Level\"] == \"district\"].copy()\n",
    "df_pincodes  = df[df[\"Entity_Level\"] == \"pincode\"].copy()\n",
    "\n",
    "print(\"District rows:\", len(df_districts))\n",
    "print(\"Pincode rows:\", len(df_pincodes))\n",
    "\n",
    "out_dir = \"/Users/kishore_kumar/PhonePe/pulse/csv_out\"\n",
    "\n",
    "df_districts.to_csv(f\"{out_dir}/top_transaction_state_districts.csv\", index=False)\n",
    "df_pincodes.to_csv(f\"{out_dir}/top_transaction_state_pincodes.csv\", index=False)\n",
    "\n",
    "print(\"✅ Wrote two separate CSVs:\")\n",
    "print(f\"{out_dir}/top_transaction_state_districts.csv\")\n",
    "print(f\"{out_dir}/top_transaction_state_pincodes.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5812f2",
   "metadata": {},
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# ======= Configure these two paths =======\n",
    "ROOT = Path(\"/Users/kishore_kumar/PhonePe/pulse/data\")  # path to the repo's data/ folder\n",
    "OUT  = Path(\"/Users/kishore_kumar/PhonePe/pulse/csv_out\")\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _safe_int(s):\n",
    "    try: return int(s)\n",
    "    except: return None\n",
    "\n",
    "def _iter_quarters(dir_path: Path):\n",
    "    qfiles = [f for f in dir_path.iterdir() if f.suffix == \".json\"]\n",
    "    return sorted(qfiles, key=lambda p: _safe_int(p.stem) if p.stem.isdigit() else 999)\n",
    "\n",
    "# ---------- COUNTRY LEVEL HELPERS ----------\n",
    "def _top_country_common(base: Path, users_mode: bool):\n",
    "    \"\"\"\n",
    "    Reads country-level top files at base=.../data/top/<type>/country/india\n",
    "    Writes three CSVs per type: states, districts, pincodes\n",
    "    \"\"\"\n",
    "    if not base.exists():\n",
    "        raise FileNotFoundError(f\"Not found: {base}\")\n",
    "\n",
    "    rows_states = []\n",
    "    rows_districts = []\n",
    "    rows_pincodes = []\n",
    "\n",
    "    for year_dir in sorted([d for d in base.iterdir() if d.is_dir() and d.name != \"state\"], key=lambda p: int(p.name)):\n",
    "        year = int(year_dir.name)\n",
    "        for qfile in _iter_quarters(year_dir):\n",
    "            with qfile.open(\"r\", encoding=\"utf-8\") as f:\n",
    "                js = json.load(f)\n",
    "            data = (js or {}).get(\"data\", {}) or {}\n",
    "\n",
    "            # STATES (country-level has states)\n",
    "            for e in data.get(\"states\", []) or []:\n",
    "                if users_mode:\n",
    "                    rows_states.append({\n",
    "                        \"Year\": year, \"Quarter\": int(qfile.stem),\n",
    "                        \"Entity\": e.get(\"name\"),\n",
    "                        \"Registered_users\": e.get(\"registeredUsers\")\n",
    "                    })\n",
    "                else:\n",
    "                    m = e.get(\"metric\", {}) or {}\n",
    "                    rows_states.append({\n",
    "                        \"Year\": year, \"Quarter\": int(qfile.stem),\n",
    "                        \"Entity\": e.get(\"entityName\"),\n",
    "                        \"Metric_type\": m.get(\"type\"),\n",
    "                        \"Count\": m.get(\"count\"),\n",
    "                        \"Amount\": m.get(\"amount\"),\n",
    "                    })\n",
    "\n",
    "            # DISTRICTS\n",
    "            for e in data.get(\"districts\", []) or []:\n",
    "                if users_mode:\n",
    "                    rows_districts.append({\n",
    "                        \"Year\": year, \"Quarter\": int(qfile.stem),\n",
    "                        \"Entity\": e.get(\"name\"),\n",
    "                        \"Registered_users\": e.get(\"registeredUsers\")\n",
    "                    })\n",
    "                else:\n",
    "                    m = e.get(\"metric\", {}) or {}\n",
    "                    rows_districts.append({\n",
    "                        \"Year\": year, \"Quarter\": int(qfile.stem),\n",
    "                        \"Entity\": e.get(\"entityName\"),\n",
    "                        \"Metric_type\": m.get(\"type\"),\n",
    "                        \"Count\": m.get(\"count\"),\n",
    "                        \"Amount\": m.get(\"amount\"),\n",
    "                    })\n",
    "\n",
    "            # PINCODES\n",
    "            for e in data.get(\"pincodes\", []) or []:\n",
    "                if users_mode:\n",
    "                    rows_pincodes.append({\n",
    "                        \"Year\": year, \"Quarter\": int(qfile.stem),\n",
    "                        \"Entity\": e.get(\"name\"),\n",
    "                        \"Registered_users\": e.get(\"registeredUsers\")\n",
    "                    })\n",
    "                else:\n",
    "                    m = e.get(\"metric\", {}) or {}\n",
    "                    rows_pincodes.append({\n",
    "                        \"Year\": year, \"Quarter\": int(qfile.stem),\n",
    "                        \"Entity\": e.get(\"entityName\"),\n",
    "                        \"Metric_type\": m.get(\"type\"),\n",
    "                        \"Count\": m.get(\"count\"),\n",
    "                        \"Amount\": m.get(\"amount\"),\n",
    "                    })\n",
    "\n",
    "    return rows_states, rows_districts, rows_pincodes\n",
    "\n",
    "# ---------- STATE LEVEL HELPERS ----------\n",
    "def _top_state_common(base: Path, users_mode: bool):\n",
    "    \"\"\"\n",
    "    Reads state-level top files at base=.../data/top/<type>/country/india/state\n",
    "    Writes two CSVs per type: districts, pincodes (README: no 'states' at state-level)\n",
    "    \"\"\"\n",
    "    if not base.exists():\n",
    "        raise FileNotFoundError(f\"Not found: {base}\")\n",
    "\n",
    "    rows_districts = []\n",
    "    rows_pincodes = []\n",
    "\n",
    "    for state_dir in sorted([d for d in base.iterdir() if d.is_dir()]):\n",
    "        state = state_dir.name\n",
    "        for year_dir in sorted([d for d in state_dir.iterdir() if d.is_dir()], key=lambda p: int(p.name)):\n",
    "            year = int(year_dir.name)\n",
    "            for qfile in _iter_quarters(year_dir):\n",
    "                with qfile.open(\"r\", encoding=\"utf-8\") as f:\n",
    "                    js = json.load(f)\n",
    "                data = (js or {}).get(\"data\", {}) or {}\n",
    "\n",
    "                # DISTRICTS\n",
    "                for e in data.get(\"districts\", []) or []:\n",
    "                    if users_mode:\n",
    "                        rows_districts.append({\n",
    "                            \"State\": state, \"Year\": year, \"Quarter\": int(qfile.stem),\n",
    "                            \"Entity\": e.get(\"name\"),\n",
    "                            \"Registered_users\": e.get(\"registeredUsers\")\n",
    "                        })\n",
    "                    else:\n",
    "                        m = e.get(\"metric\", {}) or {}\n",
    "                        rows_districts.append({\n",
    "                            \"State\": state, \"Year\": year, \"Quarter\": int(qfile.stem),\n",
    "                            \"Entity\": e.get(\"entityName\"),\n",
    "                            \"Metric_type\": m.get(\"type\"),\n",
    "                            \"Count\": m.get(\"count\"),\n",
    "                            \"Amount\": m.get(\"amount\"),\n",
    "                        })\n",
    "\n",
    "                # PINCODES\n",
    "                for e in data.get(\"pincodes\", []) or []:\n",
    "                    if users_mode:\n",
    "                        rows_pincodes.append({\n",
    "                            \"State\": state, \"Year\": year, \"Quarter\": int(qfile.stem),\n",
    "                            \"Entity\": e.get(\"name\"),\n",
    "                            \"Registered_users\": e.get(\"registeredUsers\")\n",
    "                        })\n",
    "                    else:\n",
    "                        m = e.get(\"metric\", {}) or {}\n",
    "                        rows_pincodes.append({\n",
    "                            \"State\": state, \"Year\": year, \"Quarter\": int(qfile.stem),\n",
    "                            \"Entity\": e.get(\"entityName\"),\n",
    "                            \"Metric_type\": m.get(\"type\"),\n",
    "                            \"Count\": m.get(\"count\"),\n",
    "                            \"Amount\": m.get(\"amount\"),\n",
    "                        })\n",
    "\n",
    "    return rows_districts, rows_pincodes\n",
    "\n",
    "# ---------- TRANSACTION ----------\n",
    "def top_transaction_country():\n",
    "    base = ROOT / \"top\" / \"transaction\" / \"country\" / \"india\"\n",
    "    st, di, pi = _top_country_common(base, users_mode=False)\n",
    "    pd.DataFrame(st).sort_values([\"Year\",\"Quarter\",\"Entity\"], ignore_index=True)\\\n",
    "        .to_csv(OUT / \"top_transactions_states_country.csv\", index=False)\n",
    "    pd.DataFrame(di).sort_values([\"Year\",\"Quarter\",\"Entity\"], ignore_index=True)\\\n",
    "        .to_csv(OUT / \"top_transactions_districts_country.csv\", index=False)\n",
    "    pd.DataFrame(pi).sort_values([\"Year\",\"Quarter\",\"Entity\"], ignore_index=True)\\\n",
    "        .to_csv(OUT / \"top_transactions_pincodes_country.csv\", index=False)\n",
    "\n",
    "def top_transaction_state():\n",
    "    base = ROOT / \"top\" / \"transaction\" / \"country\" / \"india\" / \"state\"\n",
    "    di, pi = _top_state_common(base, users_mode=False)\n",
    "    pd.DataFrame(di).sort_values([\"State\",\"Year\",\"Quarter\",\"Entity\"], ignore_index=True)\\\n",
    "        .to_csv(OUT / \"top_transactions_districts_state.csv\", index=False)\n",
    "    pd.DataFrame(pi).sort_values([\"State\",\"Year\",\"Quarter\",\"Entity\"], ignore_index=True)\\\n",
    "        .to_csv(OUT / \"top_transactions_pincodes_state.csv\", index=False)\n",
    "\n",
    "# ---------- INSURANCE ----------\n",
    "def top_insurance_country():\n",
    "    base = ROOT / \"top\" / \"insurance\" / \"country\" / \"india\"\n",
    "    st, di, pi = _top_country_common(base, users_mode=False)\n",
    "    pd.DataFrame(st).sort_values([\"Year\",\"Quarter\",\"Entity\"], ignore_index=True)\\\n",
    "        .to_csv(OUT / \"top_insurance_states_country.csv\", index=False)\n",
    "    pd.DataFrame(di).sort_values([\"Year\",\"Quarter\",\"Entity\"], ignore_index=True)\\\n",
    "        .to_csv(OUT / \"top_insurance_districts_country.csv\", index=False)\n",
    "    pd.DataFrame(pi).sort_values([\"Year\",\"Quarter\",\"Entity\"], ignore_index=True)\\\n",
    "        .to_csv(OUT / \"top_insurance_pincodes_country.csv\", index=False)\n",
    "\n",
    "def top_insurance_state():\n",
    "    base = ROOT / \"top\" / \"insurance\" / \"country\" / \"india\" / \"state\"\n",
    "    di, pi = _top_state_common(base, users_mode=False)\n",
    "    pd.DataFrame(di).sort_values([\"State\",\"Year\",\"Quarter\",\"Entity\"], ignore_index=True)\\\n",
    "        .to_csv(OUT / \"top_insurance_districts_state.csv\", index=False)\n",
    "    pd.DataFrame(pi).sort_values([\"State\",\"Year\",\"Quarter\",\"Entity\"], ignore_index=True)\\\n",
    "        .to_csv(OUT / \"top_insurance_pincodes_state.csv\", index=False)\n",
    "\n",
    "# ---------- USER ----------\n",
    "def top_user_country():\n",
    "    base = ROOT / \"top\" / \"user\" / \"country\" / \"india\"\n",
    "    st, di, pi = _top_country_common(base, users_mode=True)\n",
    "    pd.DataFrame(st).sort_values([\"Year\",\"Quarter\",\"Entity\"], ignore_index=True)\\\n",
    "        .to_csv(OUT / \"top_users_states_country.csv\", index=False)\n",
    "    pd.DataFrame(di).sort_values([\"Year\",\"Quarter\",\"Entity\"], ignore_index=True)\\\n",
    "        .to_csv(OUT / \"top_users_districts_country.csv\", index=False)\n",
    "    pd.DataFrame(pi).sort_values([\"Year\",\"Quarter\",\"Entity\"], ignore_index=True)\\\n",
    "        .to_csv(OUT / \"top_users_pincodes_country.csv\", index=False)\n",
    "\n",
    "def top_user_state():\n",
    "    base = ROOT / \"top\" / \"user\" / \"country\" / \"india\" / \"state\"\n",
    "    di, pi = _top_state_common(base, users_mode=True)\n",
    "    pd.DataFrame(di).sort_values([\"State\",\"Year\",\"Quarter\",\"Entity\"], ignore_index=True)\\\n",
    "        .to_csv(OUT / \"top_users_districts_state.csv\", index=False)\n",
    "    pd.DataFrame(pi).sort_values([\"State\",\"Year\",\"Quarter\",\"Entity\"], ignore_index=True)\\\n",
    "        .to_csv(OUT / \"top_users_pincodes_state.csv\", index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    top_transaction_country()\n",
    "    top_transaction_state()\n",
    "    top_insurance_country()\n",
    "    top_insurance_state()\n",
    "    top_user_country()\n",
    "    top_user_state()\n",
    "    print(\"[OK] Wrote Top CSVs to:\", OUT)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
